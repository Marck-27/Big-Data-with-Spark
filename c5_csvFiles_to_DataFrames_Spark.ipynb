{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto: Creación de Data Frames Spark a partir de archivos .csv \n",
    "\n",
    "En la presente práctica veremos cómo:\n",
    "\n",
    "* Crear Data Frames a partir archivos .csv\n",
    "\n",
    "Algunas funciones que veremos son:\n",
    "\n",
    "`.show(N)` Muestra los primeros N registros de un Data Frame (análogo al `.take(N)` para RDDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para crear punto de conexión:\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Cargamos libreria para crear Data Frames:\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "#from pyspark.sql import SparkSession\n",
    "\n",
    "# Cargamos librerias para crear el schema del DataFrame\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "\n",
    "# Cargamos los tipos de datos que usaremos para crear las columnas de los dataframes:\n",
    "from pyspark.sql.types import  IntegerType, StringType, FloatType\n",
    "\n",
    "#from pyspark.sql.types import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el punto de conexió a Spark (que se ejecutará en mi máquina 'local'):\n",
    "spark = SparkContext(master='local', appName='DataFrames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marck/.local/lib/python3.8/site-packages/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Creamos el contexto para SQL:\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte.csv\t deportistaError.csv  modelo_relacional.jpg\n",
      "deportista2.csv  evento.csv\t      paises.csv\n",
      "deportista.csv\t juegos.csv\t      resultados.csv\n"
     ]
    }
   ],
   "source": [
    "!ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",nombre_juego,annio,temporada,ciudad\n",
      "1,1896 Verano,1896,Verano,Athina\n",
      "2,1900 Verano,1900,Verano,Paris\n",
      "3,1904 Verano,1904,Verano,St. Louis\n",
      "4,1906 Verano,1906,Verano,Athina\n"
     ]
    }
   ],
   "source": [
    "# Vemos las primeras 5 líneas del archivo 'juegos.csv'\n",
    "\n",
    "!head -n 5 Data/juegos.csv\n",
    "\n",
    "# Veremos que el archivo ya tiene un encabezado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la ruta de acceso a los archivos:\n",
    "path = './Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de cargar un archivo, creamos un esquema, es decir,\n",
    "# creamos la estructura de la trabla en donde vamos a cargar la infomración:\n",
    "juegoSchema = StructType([\n",
    "    StructField( 'juego_id', IntegerType(), False ),\n",
    "    StructField( 'anio_estacion', StringType(), False ),\n",
    "    StructField( 'anio', IntegerType(), False ),\n",
    "    StructField('temporada', StringType(), False ),\n",
    "    StructField('ciudad', StringType(), False )\n",
    "    ])\n",
    "\n",
    "# StructField <-- instrucción para crear una columna, se debe especificar el tipo de dato que almacenará\n",
    "# En caso de que el campo pueda ser nulo ponemos 'True' de lo contrario ponemos 'False'\n",
    "\n",
    "# Una vez creado el schema, cargamos la información:\n",
    "juegoDF = sqlContext.read.schema(juegoSchema).option('header',True).csv( path+'juegos.csv' )\n",
    "\n",
    "# .option('header',True)    <-- indica que el archvio que vamos a cargar ya tiene un encabezado \n",
    "# .csv( path+'juegos.csv' ) <-- instrucción que carga el archivo '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+----+---------+------------+\n",
      "|juego_id|anio_estacion|anio|temporada|      ciudad|\n",
      "+--------+-------------+----+---------+------------+\n",
      "|       1|  1896 Verano|1896|   Verano|      Athina|\n",
      "|       2|  1900 Verano|1900|   Verano|       Paris|\n",
      "|       3|  1904 Verano|1904|   Verano|   St. Louis|\n",
      "|       4|  1906 Verano|1906|   Verano|      Athina|\n",
      "|       5|  1908 Verano|1908|   Verano|      London|\n",
      "|       6|  1912 Verano|1912|   Verano|   Stockholm|\n",
      "|       7|  1920 Verano|1920|   Verano|   Antwerpen|\n",
      "|       8|1924 Invierno|1924| Invierno|    Chamonix|\n",
      "|       9|  1924 Verano|1924|   Verano|       Paris|\n",
      "|      10|1928 Invierno|1928| Invierno|Sankt Moritz|\n",
      "+--------+-------------+----+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos la acción '.show()' para poder ver el contenido de los primeros N registros:\n",
    "N=10\n",
    "\n",
    "# La información de DataFrames se muestra con '.show()'\n",
    "# La información de RDDs se muestra con '.take()'\n",
    "juegoDF.show(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.79:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrames</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=DataFrames>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejecutamos la interfaz gráfica de spark dando click en el link:\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerramos sesión para liberar memoria:\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
