{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto: Persistencia de información\n",
    "\n",
    "La persistencia se refiere al respaldo de información (en disco o memoria) de un Data Frame o RDD con el objetivo de evitar pérdidas de información.\n",
    "\n",
    "Algunas de las funciones que veremos son:\n",
    "\n",
    "`.is_cached` <-- Verifica si un Data Frame o RDD esta en memoria computacional \n",
    "\n",
    "`.rdd.cache()` <-- Guarda un rdd en memoria\n",
    "\n",
    "`.rdd.getStorageLevel()` <-- Verifica las caracteriasticas de persistencia\n",
    "\n",
    "`.rdd.unpersist()` <-- Elimina la persistenca de información\n",
    "\n",
    "`.rdd.persist()` <-- Aplica persistenca de información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para crear punto de conexión:\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Cargamos libreria para crear Data Frames:\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "#from pyspark.sql import SparkSession\n",
    "\n",
    "# Cargamos librerias para crear el schema del DataFrame\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "\n",
    "# Cargamos los tipos de datos que usaremos para crear las columnas de los dataframes:\n",
    "from pyspark.sql.types import  IntegerType, StringType, FloatType\n",
    "\n",
    "#from pyspark.sql.types import Row\n",
    "\n",
    "# Importamos functions especiales, entre ellas la función 'col'\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Importamos libreria para peristencia:\n",
    "from pyspark.storagelevel import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el punto de conexió a Spark (que se ejecutará en mi máquina 'local'):\n",
    "spark = SparkContext(master='local', appName='Persistencia_Particionado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marck/.local/lib/python3.8/site-packages/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Creamos el contexto para SQL:\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte.csv\t deportistaError.csv  modelo_relacional.jpg\n",
      "deportista2.csv  evento.csv\t      paises.csv\n",
      "deportista.csv\t juegos.csv\t      resultados.csv\n"
     ]
    }
   ],
   "source": [
    "# Visualizamos el contenido de la carpeta 'Data' \n",
    "!ls ./Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta en donde se encuentran los datos con los que trabajaremos:\n",
    "path = './Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos función para eliminar encabezados en RDDs:\n",
    "def eliminaEncabezado(indice , interador):\n",
    "    return iter( list(interador)[1:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de registros a visualizar:\n",
    "N=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un DataFrame con los datos del archivo *paises.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,equipo,sigla\n",
      "1,30. Februar,AUT\n",
      "2,A North American Team,MEX\n",
      "3,Acipactli,MEX\n",
      "4,Acturus,ARG\n"
     ]
    }
   ],
   "source": [
    "# Exploramos archivo.cvs para verificar si trae encabezado:\n",
    "\n",
    "!head -n 5 Data/paises.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+\n",
      "| id|              equipo|sigla|\n",
      "+---+--------------------+-----+\n",
      "|  1|         30. Februar|  AUT|\n",
      "|  2|A North American ...|  MEX|\n",
      "|  3|           Acipactli|  MEX|\n",
      "|  4|             Acturus|  ARG|\n",
      "|  5|         Afghanistan|  AFG|\n",
      "+---+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Guardamos archivo.csv en un DataFrame:\n",
    "\n",
    "# Creamos un Schema para el DataFrame, es decir, \n",
    "# Asignamos nombre a las columnas, especificamos su tipo de dato y especificamos si el campo puede ser nulo\n",
    "paisesSchema = StructType([\n",
    "    StructField('id',IntegerType(),False),\n",
    "    StructField('equipo',StringType(),False),\n",
    "    StructField('sigla',StringType(),False) \n",
    "])\n",
    "\n",
    "# Creamos el DataFrame:\n",
    "paisesDF = sqlContext.read.schema(paisesSchema).option('header', 'true').csv(path+'paises.csv')\n",
    "\n",
    "# La información de RDDs se muestra con '.take()'\n",
    "# La información de DataFrames se muestra con '.show()'\n",
    "paisesDF.show(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un DataFrame con los datos del archivo *deporte.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte_id,deporte\n",
      "1,Basketball\n",
      "2,Judo\n",
      "3,Football\n",
      "4,Tug-Of-War\n"
     ]
    }
   ],
   "source": [
    "# Exploramos archivo.cvs para verificar si trae encabezado:\n",
    "\n",
    "!head -n 5 Data/deporte.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|deporte_id|      deporte|\n",
      "+----------+-------------+\n",
      "|         1|   Basketball|\n",
      "|         2|         Judo|\n",
      "|         3|     Football|\n",
      "|         4|   Tug-Of-War|\n",
      "|         5|Speed Skating|\n",
      "+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Guardamos archivo.csv en un DataFrame:\n",
    "\n",
    "# Creamos un Schema para el DataFrame, es decir, \n",
    "# Asignamos nombre a las columnas, especificamos su tipo de dato y especificamos si el campo puede ser nulo\n",
    "deportesSchema = StructType([\n",
    "    StructField('deporte_id',IntegerType(),False),\n",
    "    StructField('deporte',StringType(),False) \n",
    "])\n",
    "\n",
    "# Creamos el DataFrame:\n",
    "deportesDF = sqlContext.read.schema(deportesSchema).option('header', 'true').csv(path+'deporte.csv')\n",
    "\n",
    "# La información de RDDs se muestra con '.take()'\n",
    "# La información de DataFrames se muestra con '.show()'\n",
    "deportesDF.show(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un DataFrame con los datos del archivo *evento.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evento_id,evento,deporte_id\n",
      "1,Basketball Men's Basketball,1\n",
      "2,Judo Men's Extra-Lightweight,2\n",
      "3,Football Men's Football,3\n",
      "4,Tug-Of-War Men's Tug-Of-War,4\n"
     ]
    }
   ],
   "source": [
    "# Exploramos archivo.cvs para verificar si trae encabezado:\n",
    "\n",
    "!head -n 5 Data/evento.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+\n",
      "|evento_id|              nombre|deporte_id|\n",
      "+---------+--------------------+----------+\n",
      "|        1|Basketball Men's ...|         1|\n",
      "|        2|Judo Men's Extra-...|         2|\n",
      "|        3|Football Men's Fo...|         3|\n",
      "|        4|Tug-Of-War Men's ...|         4|\n",
      "|        5|Speed Skating Wom...|         5|\n",
      "+---------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Guardamos archivo.csv en un DataFrame:\n",
    "\n",
    "# Creamos un Schema para el DataFrame, es decir, \n",
    "# Asignamos nombre a las columnas, especificamos su tipo de dato y especificamos si el campo puede ser nulo\n",
    "eventoSchema = StructType([\n",
    "    StructField('evento_id',IntegerType(),False),\n",
    "    StructField('nombre',StringType(),False),\n",
    "    StructField('deporte_id',IntegerType(),False) \n",
    "])\n",
    "\n",
    "# Creamos el DataFrame:\n",
    "deportesOlimpicosDF = sqlContext.read.schema(eventoSchema).option('header', 'true').csv(path+'evento.csv')\n",
    "\n",
    "# La información de RDDs se muestra con '.take()'\n",
    "# La información de DataFrames se muestra con '.show()'\n",
    "deportesOlimpicosDF.show(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un DataFrame con los datos del archivo *resultados.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultado_id,medalla,deportista_id,juego_id,evento_id\n",
      "1,NA,1,39,1\n",
      "2,NA,2,49,2\n",
      "3,NA,3,7,3\n",
      "4,Gold,4,2,4\n"
     ]
    }
   ],
   "source": [
    "# Exploramos archivo.cvs para verificar si trae encabezado:\n",
    "\n",
    "!head -n 5 Data/resultados.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-------------+--------+---------+\n",
      "|resultado_id|medalla|deportista_id|juego_id|evento_id|\n",
      "+------------+-------+-------------+--------+---------+\n",
      "|           1|     NA|            1|      39|        1|\n",
      "|           2|     NA|            2|      49|        2|\n",
      "|           3|     NA|            3|       7|        3|\n",
      "|           4|   Gold|            4|       2|        4|\n",
      "|           5|     NA|            5|      36|        5|\n",
      "+------------+-------+-------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Guardamos archivo.csv en un DataFrame:\n",
    "\n",
    "# Creamos un Schema para el DataFrame, es decir, \n",
    "# Asignamos nombre a las columnas, especificamos su tipo de dato y especificamos si el campo puede ser nulo\n",
    "resultadoSchema = StructType([\n",
    "    StructField('resultado_id',IntegerType(),False),\n",
    "    StructField('medalla',StringType(),False),\n",
    "    StructField('deportista_id',IntegerType(),False),\n",
    "    StructField('juego_id',IntegerType(),False),\n",
    "    StructField('evento_id',IntegerType(),False)\n",
    "])\n",
    "\n",
    "# Creamos el DataFrame:\n",
    "resultadoDF = sqlContext.read.schema(resultadoSchema).option('header', 'true').csv(path+'resultados.csv')\n",
    "\n",
    "# La información de RDDs se muestra con '.take()'\n",
    "# La información de DataFrames se muestra con '.show()'\n",
    "resultadoDF.show(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un DataFrame con los datos del archivo *juegos.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",nombre_juego,annio,temporada,ciudad\n",
      "1,1896 Verano,1896,Verano,Athina\n",
      "2,1900 Verano,1900,Verano,Paris\n",
      "3,1904 Verano,1904,Verano,St. Louis\n",
      "4,1906 Verano,1906,Verano,Athina\n"
     ]
    }
   ],
   "source": [
    "# Exploramos archivo.cvs para verificar si trae encabezado:\n",
    "\n",
    "!head -n 5 Data/juegos.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----+---------+---------+\n",
      "|juego_id|nombre_juego|anio|temporada|   ciudad|\n",
      "+--------+------------+----+---------+---------+\n",
      "|       1| 1896 Verano|1896|   Verano|   Athina|\n",
      "|       2| 1900 Verano|1900|   Verano|    Paris|\n",
      "|       3| 1904 Verano|1904|   Verano|St. Louis|\n",
      "|       4| 1906 Verano|1906|   Verano|   Athina|\n",
      "|       5| 1908 Verano|1908|   Verano|   London|\n",
      "+--------+------------+----+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Guardamos archivo.csv en un DataFrame:\n",
    "\n",
    "# Creamos un Schema para el DataFrame, es decir, \n",
    "# Asignamos nombre a las columnas, especificamos su tipo de dato y especificamos si el campo puede ser nulo\n",
    "juegoSchema = StructType([\n",
    "    StructField('juego_id',IntegerType(),False),\n",
    "    StructField('nombre_juego',StringType(),False),\n",
    "    StructField('anio',IntegerType(),False),\n",
    "    StructField('temporada',StringType(),False),\n",
    "    StructField('ciudad',StringType(),False)\n",
    "])\n",
    "\n",
    "# Creamos el DataFrame:\n",
    "juegoDF = sqlContext.read.schema(juegoSchema).option('header', 'true').csv(path+'juegos.csv')\n",
    "\n",
    "# La información de RDDs se muestra con '.take()'\n",
    "# La información de DataFrames se muestra con '.show()'\n",
    "juegoDF.show(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+---------+---------+\n",
      "|juego_id|anio|temporada|   ciudad|\n",
      "+--------+----+---------+---------+\n",
      "|       1|1896|   Verano|   Athina|\n",
      "|       2|1900|   Verano|    Paris|\n",
      "|       3|1904|   Verano|St. Louis|\n",
      "|       4|1906|   Verano|   Athina|\n",
      "|       5|1908|   Verano|   London|\n",
      "+--------+----+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos la una columna del Data Frame:\n",
    "juegoDF = juegoDF.drop('nombre_juego')\n",
    "\n",
    "juegoDF.show(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un DataFrame con los datos de los archivos *deportista.csv* y *deportista2.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deportista_id,nombre,genero,edad,altura,peso,equipo_id\n",
      "1,A Dijiang,1,24,180,80,199\n",
      "2,A Lamusi,1,23,170,60,199\n",
      "3,Gunnar Nielsen Aaby,1,24,0,0,273\n",
      "4,Edgar Lindenau Aabye,1,34,0,0,278\n"
     ]
    }
   ],
   "source": [
    "# Exploramos archivo.cvs para verificar si trae encabezado:\n",
    "\n",
    "!head -n 5 Data/deportista.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67787,Lee BongJu,1,27,167,56,970\n",
      "67788,Lee BuTi,1,23,164,54,203\n",
      "67789,Anthony N. Buddy Lee,1,34,172,62,1096\n",
      "67790,Alfred A. Butch Lee Porter,1,19,186,80,825\n",
      "67791,Lee ByeongGu,1,22,175,68,970\n"
     ]
    }
   ],
   "source": [
    "# Exploramos archivo.cvs para verificar si trae encabezado:\n",
    "\n",
    "!head -n 5 Data/deportista2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que el archivo 'deportista.csv' tiene encabezado y 'deportista2.csv' no tiene\n",
    "\n",
    "El archivo 'deportista2.csv' es continuación de 'deportista.csv'\n",
    "\n",
    "Para hacer un sólo Data Frame, haremos lo siguiente: \n",
    "\n",
    "1. Tranformamos los archivos.csv a RDDs\n",
    "\n",
    "2. Eliminamos el encabezado del archivo 'deportista.csv'\n",
    "\n",
    "3. Unimos los RDDs 'deportista' y 'deportista2\n",
    "\n",
    "4. Ya que tenemos un sólo RDD lo pasamos a un Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos archivos.csv en RDDs:\n",
    "# .map(lambda l : l.split(',')) <-- Le asigan formato al contenido de archivos .csv\n",
    "\n",
    "deportistaOlimpicoRDD = spark.textFile(path+'deportista.csv').map(lambda l : l.split(','))\n",
    "\n",
    "deportistaOlimpicoRDD2 = spark.textFile(path+'deportista2.csv').map(lambda l : l.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deportista_id', 'nombre', 'genero', 'edad', 'altura', 'peso', 'equipo_id'],\n",
       " ['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199'],\n",
       " ['3', 'Gunnar Nielsen Aaby', '1', '24', '0', '0', '273'],\n",
       " ['4', 'Edgar Lindenau Aabye', '1', '34', '0', '0', '278']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vemos los primeros N registros del RDD:\n",
    "deportistaOlimpicoRDD.take(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199'],\n",
       " ['3', 'Gunnar Nielsen Aaby', '1', '24', '0', '0', '273'],\n",
       " ['4', 'Edgar Lindenau Aabye', '1', '34', '0', '0', '278'],\n",
       " ['5', 'Christine Jacoba Aaftink', '2', '21', '185', '82', '705']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminamos encabezado al primer RDD :\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.mapPartitionsWithIndex(eliminaEncabezado)\n",
    "\n",
    "# Vemos los primeros N registros del RDD:\n",
    "deportistaOlimpicoRDD.take(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['67787', 'Lee BongJu', '1', '27', '167', '56', '970'],\n",
       " ['67788', 'Lee BuTi', '1', '23', '164', '54', '203'],\n",
       " ['67789', 'Anthony N. Buddy Lee', '1', '34', '172', '62', '1096'],\n",
       " ['67790', 'Alfred A. Butch Lee Porter', '1', '19', '186', '80', '825'],\n",
       " ['67791', 'Lee ByeongGu', '1', '22', '175', '68', '970']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vemos los primeros N registros del segundo RDD:\n",
    "deportistaOlimpicoRDD2.take(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos los 2 RDDs: deportistaOlimpicoRDD y deportistaOlimpicoRDD2\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.union( deportistaOlimpicoRDD2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|            1|           A Dijiang|     1|  24|   180|80.0|      199|\n",
      "|            2|            A Lamusi|     1|  23|   170|60.0|      199|\n",
      "|            3| Gunnar Nielsen Aaby|     1|  24|     0| 0.0|      273|\n",
      "|            4|Edgar Lindenau Aabye|     1|  34|     0| 0.0|      278|\n",
      "|            5|Christine Jacoba ...|     2|  21|   185|82.0|      705|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creación de un Data Frame a partir de un RDD:\n",
    "\n",
    "# Corregimos los tipos de dato en cada columna del RDD: \n",
    "deportistaOlimpicoRDD = \\\n",
    "    deportistaOlimpicoRDD.map(lambda x: ( int(x[0]), x[1],  int(x[2]), int(x[3]), int(x[4]), float(x[5]), int(x[6])  ) )\n",
    "\n",
    "\n",
    "# A continuación creamos el schema, es decir, la estructura (columnas) del Data Frame donde pondremos los datos del RDD:\n",
    "schema = StructType([\n",
    "    StructField('deportista_id', IntegerType(), False ),\n",
    "    StructField('nombre', StringType(), False ),\n",
    "    StructField('genero', IntegerType(), False ),\n",
    "    StructField('edad', IntegerType(), False ),\n",
    "    StructField('altura', IntegerType(), False ),\n",
    "    StructField('peso', FloatType(), False ),\n",
    "    StructField('equipo_id', IntegerType(), False )\n",
    "    ])\n",
    "\n",
    "# StructField <-- instrucción para crear una columna, se debe especificar el tipo de dato que almacenará\n",
    "# En caso de que el campo pueda ser nulo ponemos 'True' de lo contrario ponemos 'False'\n",
    "\n",
    "\n",
    "# Creamos el DataFrame a partir del RDD:\n",
    "deportistaOlimpicoDF = sqlContext.createDataFrame(deportistaOlimpicoRDD, schema)\n",
    "\n",
    "\n",
    "# La información de RDDs se muestra con '.take()'\n",
    "# La información de DataFrames se muestra con '.show()'\n",
    "deportistaOlimpicoDF.show(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|          133|           Franz Abb|     1|   0|     0| 0.0|      399|\n",
      "|          167|Ould Lamine Abdallah|     1|   0|     0| 0.0|      362|\n",
      "|           66|     Mohamed Abakkar|     1|   0|   156|48.0|     1003|\n",
      "|          163|     Ismail Abdallah|     1|   0|     0| 0.0|     1095|\n",
      "|          139|George Ioannis Abbot|     1|   0|     0| 0.0|     1043|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vemos los primeros N registros ordenadas de forma ascendente \n",
    "# con respecto a los valores de la columna 'edadAlJugar'\n",
    "\n",
    "deportistaOlimpicoDF.sort('edad').show(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos con registros donde los valores de la columna 'edad' sean distintos de cero\n",
    "deportistaOlimpicoDF = deportistaOlimpicoDF.filter( (deportistaOlimpicoDF['edad'] !=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|        71691|  Dimitrios Loundras|     1|  10|     0| 0.0|      333|\n",
      "|        52070|        Etsuko Inada|     2|  11|     0| 0.0|      514|\n",
      "|        40129|    Luigina Giavotti|     2|  11|     0| 0.0|      507|\n",
      "|        37333|Carlos Bienvenido...|     1|  11|     0| 0.0|      982|\n",
      "|        47618|Sonja Henie Toppi...|     2|  11|   155|45.0|      742|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostramos los primeros registros ordenados con respecto a los valores de la columna 'edad'\n",
    "deportistaOlimpicoDF.sort('edad').show(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join entre 6 DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------+--------------------+--------------------+--------------------+\n",
      "|sigla|anio|medalla|Nombre subdisciplina|   Nombre disciplina|              nombre|\n",
      "+-----+----+-------+--------------------+--------------------+--------------------+\n",
      "|  CHN|1992|     NA|Basketball Men's ...|          Basketball|           A Dijiang|\n",
      "|  CHN|2012|     NA|Judo Men's Extra-...|                Judo|            A Lamusi|\n",
      "|  DEN|1920|     NA|Football Men's Fo...|            Football| Gunnar Nielsen Aaby|\n",
      "|  SWE|1900|   Gold|Tug-Of-War Men's ...|          Tug-Of-War|Edgar Lindenau Aabye|\n",
      "|  NED|1994|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED|1994|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED|1992|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED|1992|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED|1988|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  NED|1988|     NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|  USA|1994|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1994|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1994|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1994|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1992|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1992|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1992|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1992|     NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|  USA|1994|     NA|Cross Country Ski...|Cross Country Skiing|        John Aalberg|\n",
      "|  USA|1994|     NA|Cross Country Ski...|Cross Country Skiing|        John Aalberg|\n",
      "+-----+----+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medallistaXAnio = deportistaOlimpicoDF.join(\n",
    "        resultadoDF, \n",
    "        deportistaOlimpicoDF['deportista_id'] == resultadoDF['deportista_id'], \n",
    "        'left'\n",
    "    ).join(\n",
    "        juegoDF, \n",
    "        juegoDF['juego_id'] == resultadoDF['juego_id'], \n",
    "        'left'\n",
    "    ).join(\n",
    "        paisesDF, \n",
    "        deportistaOlimpicoDF['equipo_id'] == paisesDF['id'], \n",
    "        'left' \n",
    "    ).join(\n",
    "        deportesOlimpicosDF, \n",
    "        deportesOlimpicosDF['evento_id'] == resultadoDF['evento_id'], \n",
    "        'left' \n",
    "    ).join(\n",
    "        deportesDF, \n",
    "        deportesOlimpicosDF['deporte_id'] == deportesDF['deporte_id'], \n",
    "        'left' \n",
    "    ).select( #<-- seleccionamos y renombramos algunas columnas\n",
    "        'sigla',\n",
    "        'anio',\n",
    "        'medalla',\n",
    "        deportesOlimpicosDF['nombre'].alias('Nombre subdisciplina'),\n",
    "        deportesDF['deporte'].alias('Nombre disciplina'),\n",
    "        deportistaOlimpicoDF['nombre']    \n",
    "    )\n",
    "\n",
    "medallistaXAnio.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------------------+-----+\n",
      "|sigla|anio|Nombre subdisciplina|count|\n",
      "+-----+----+--------------------+-----+\n",
      "|  GRE|1896|Athletics Men's 8...|    1|\n",
      "|  AUS|1896|Athletics Men's 1...|    1|\n",
      "|  GBR|1896|Tennis Men's Singles|    1|\n",
      "|  USA|1896|Athletics Men's 1...|    2|\n",
      "|  AUT|1896|Swimming Men's 10...|    1|\n",
      "|  AUS|1896|Tennis Men's Doubles|    1|\n",
      "|  HUN|1896|Athletics Men's M...|    1|\n",
      "|  GBR|1896|Weightlifting Men...|    1|\n",
      "|  HUN|1896|Swimming Men's 10...|    1|\n",
      "|  USA|1896|Athletics Men's 1...|    1|\n",
      "|  GER|1896|Athletics Men's 1...|    1|\n",
      "|  GRE|1896|Tennis Men's Singles|    2|\n",
      "|  GER|1896|Cycling Men's Roa...|    1|\n",
      "|  GBR|1896|Athletics Men's 4...|    1|\n",
      "|  FRA|1896|Fencing Men's Foi...|    2|\n",
      "|  GRE|1896|Tennis Men's Doubles|    2|\n",
      "|  GER|1896|Gymnastics Men's ...|    9|\n",
      "|  GBR|1896|Cycling Men's 12-...|    1|\n",
      "|  GER|1896|Gymnastics Men's ...|    1|\n",
      "|  USA|1896|Athletics Men's 1...|    1|\n",
      "+-----+----+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtramos los datos quedándonos con los deportistas que sí tienen medallas: \n",
    "medallistaXAnio.filter( medallistaXAnio['medalla'] != 'NA'  )\\\n",
    "    .groupBy('sigla','anio','Nombre subdisciplina')\\\n",
    "    .count()\\\n",
    "    .sort('anio')\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificamos si el Data Frame esta en memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preguntamos si el Data Frame esta en memoria:\n",
    "medallistaXAnio.is_cached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el DF no esta en memoria, así que cada vez que lo usemos Spark tendrá que recomputarlo, para evitar esto hacemos lo mandamos a cache:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos el Data Frame en cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[117] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si vamos a aplicar una persistencia, primero debemos quitar las persistencias previas (en caso de que se hayan hecho antes):\n",
    "medallistaXAnio.rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[117] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicamos peristencia de información en 'cache'\n",
    "medallistaXAnio.rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos las características del almacenamiento:\n",
    "medallistaXAnio.rdd.getStorageLevel()\n",
    "\n",
    "# 'StorageLevel(False, True, False, False, 1)' <-- indica las características de la persistencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de persistencia:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentación de los parámetros de la función `StorageLevel()` [aquí]( https://spark.apache.org/docs/2.4.6/api/python/pyspark.html#pyspark.StorageLevel )\n",
    "\n",
    "`StorageLevel(useDisk, useMemory, useOffHeap, deserialized, replication=1) `\n",
    "\n",
    "\n",
    "DISK_ONLY = StorageLevel(True, False, False, False, 1)\n",
    "\n",
    "DISK_ONLY_2 = StorageLevel(True, False, False, False, 2)\n",
    "\n",
    "MEMORY_AND_DISK = StorageLevel(True, True, False, False, 1)\n",
    "\n",
    "MEMORY_AND_DISK_2 = StorageLevel(True, True, False, False, 2)\n",
    "\n",
    "MEMORY_AND_DISK_SER = StorageLevel(True, True, False, False, 1)\n",
    "\n",
    "MEMORY_AND_DISK_SER_2 = StorageLevel(True, True, False, False, 2)\n",
    "\n",
    "MEMORY_ONLY = StorageLevel(False, True, False, False, 1)\n",
    "\n",
    "MEMORY_ONLY_2 = StorageLevel(False, True, False, False, 2)\n",
    "\n",
    "MEMORY_ONLY_SER = StorageLevel(False, True, False, False, 1)\n",
    "\n",
    "MEMORY_ONLY_SER_2 = StorageLevel(False, True, False, False, 2)¶\n",
    "\n",
    "OFF_HEAP = StorageLevel(True, True, True, False, 1)\n",
    "\n",
    "**Los números 1 y 2 al final de las instrucciones, indican el número de replicas de información**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[117] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si vamos a aplicar una persistencia, primero debemos quitar las persistencias previas:\n",
    "medallistaXAnio.rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[117] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos una persistencia de infomración:\n",
    "medallistaXAnio.rdd.persist( StorageLevel.MEMORY_AND_DISK_2 )\n",
    "\n",
    "# En caso de error, debemos quitar las persistencias previas ejecutando antes:\n",
    "# medallistaXAnio.rdd.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando un nivel de persistencia definido por el usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "StorageLevel.MEMORY_AND_DISK_3 = StorageLevel(True,True,False,False,3)\n",
    "\n",
    "# MEMORY_AND_DISK_3 <-- nombre asignado por el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[117] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si vamos a aplicar una persistencia, primero debemos quitar las persistencias previas:\n",
    "medallistaXAnio.rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[117] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicamos nuestro nivel de persistencia:\n",
    "medallistaXAnio.rdd.persist(StorageLevel.MEMORY_AND_DISK_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerramos sesión para liberar memoria:\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
