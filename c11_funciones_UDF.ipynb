{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto: Funciones definidas por el usuario (User Defined Functions: UDF)\n",
    "\n",
    "En la presente práctica veremos cómo:\n",
    "\n",
    "* Crear RDDs a partir archivos .csv\n",
    "\n",
    "* Crear Data Frames a partir de RDDs\n",
    "\n",
    "* Construcción y Aplicación de funciones UDF (Veremos como convertir el tipo de dato de una columna y asignar valor 'Null' a campos literalmente vacíos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libreria para crear punto de conexión:\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Cargamos libreria para crear Data Frames:\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "#from pyspark.sql import SparkSession\n",
    "\n",
    "# Cargamos librerias para crear el schema del DataFrame\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "\n",
    "# Cargamos los tipos de datos que usaremos para crear las columnas de los dataframes:\n",
    "from pyspark.sql.types import  IntegerType, StringType, FloatType\n",
    "\n",
    "#from pyspark.sql.types import Row\n",
    "\n",
    "# Cargamos librería para poder crear funciones UDF:\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos función para eliminar encabezados en RDDs:\n",
    "def eliminaEncabezado(indice , interador):\n",
    "    return iter( list(interador)[1:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el punto de conexió a Spark (que se ejecutará en mi máquina 'local'):\n",
    "spark = SparkContext(master='local', appName='UDF_Functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marck/.local/lib/python3.8/site-packages/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Creamos el contexto para SQL:\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte.csv\t deportistaError.csv  modelo_relacional.jpg\n",
      "deportista2.csv  evento.csv\t      paises.csv\n",
      "deportista.csv\t juegos.csv\t      resultados.csv\n"
     ]
    }
   ],
   "source": [
    "!ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deportista_id,nombre,genero,edad,altura,peso,equipo_id\n",
      "1,A Dijiang,1,24,180,80,199\n",
      "2,A Lamusi,1,23,170,60,199\n",
      "3,Gunnar Nielsen Aaby,1,24,,,273\n",
      "4,Edgar Lindenau Aabye,1,34,,,278\n"
     ]
    }
   ],
   "source": [
    "# Vemos las primeras 5 líneas del archivo 'deportistaError.csv'\n",
    "\n",
    "!head -n 5 Data/deportistaError.csv\n",
    "\n",
    "# Veremos que el archivo ya tiene un encabezado y hay algunos campos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la ruta de acceso a los archivos:\n",
    "path = './Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de registros a visualizar:\n",
    "N = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos RDD a partir de un archivo .csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos RDDs con el archivo 'deportistaError.csv'\n",
    "# .map(lambda l : l.split(',')) <-- Le asigan formato al contenido de archivos .csv\n",
    "\n",
    "deportistaErrorRDD = spark.textFile(path+'deportistaError.csv').map(lambda l : l.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deportista_id', 'nombre', 'genero', 'edad', 'altura', 'peso', 'equipo_id'],\n",
       " ['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199'],\n",
       " ['3', 'Gunnar Nielsen Aaby', '1', '24', '', '', '273'],\n",
       " ['4', 'Edgar Lindenau Aabye', '1', '34', '', '', '278']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos los primeros N registros:\n",
    "deportistaErrorRDD.take(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199'],\n",
       " ['3', 'Gunnar Nielsen Aaby', '1', '24', '', '', '273'],\n",
       " ['4', 'Edgar Lindenau Aabye', '1', '34', '', '', '278'],\n",
       " ['5', 'Christine Jacoba Aaftink', '2', '21', '185', '82', '705']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminamos encabezado del RDD :\n",
    "deportistaErrorRDD = deportistaErrorRDD.mapPartitionsWithIndex(eliminaEncabezado)\n",
    "\n",
    "# Vemos los primeros N registros del RDD:\n",
    "deportistaErrorRDD.take(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasamos RDD a un Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de un Data Frame a partir de un RDD:\n",
    "\n",
    "# En este caso (intencionalmente) no asignamos tipo de dato a las columnas del Data Frame:\n",
    "deportistaErrorRDD = \\\n",
    "    deportistaErrorRDD.map(lambda x: ( x[0], x[1],  x[2], x[3], x[4], x[5], x[6] ) )\n",
    "\n",
    "\n",
    "# A continuación creamos el schema, es decir, la estructura (columnas) del Data Frame donde pondremos los datos del RDD:\n",
    "schema = StructType([\n",
    "    StructField('deportista_id', StringType(), False ),\n",
    "    StructField('nombre', StringType(), False ),\n",
    "    StructField('genero', StringType(), False ),\n",
    "    StructField('edad', StringType(), False ),\n",
    "    StructField('altura', StringType(), False ),\n",
    "    StructField('peso', StringType(), False ),\n",
    "    StructField('equipo_id', StringType(), False )\n",
    "    ])\n",
    "\n",
    "# StructField <-- instrucción para crear una columna, se debe especificar el tipo de dato que almacenará\n",
    "# En caso de que el campo pueda ser nulo ponemos 'True' de lo contrario ponemos 'False'\n",
    "\n",
    "# Creamos el DataFrame a partir del RDD:\n",
    "deportistaErrorDF = sqlContext.createDataFrame(deportistaErrorRDD, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|deportista_id|              nombre|genero|edad|altura|peso|equipo_id|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "|            1|           A Dijiang|     1|  24|   180|  80|      199|\n",
      "|            2|            A Lamusi|     1|  23|   170|  60|      199|\n",
      "|            3| Gunnar Nielsen Aaby|     1|  24|      |    |      273|\n",
      "|            4|Edgar Lindenau Aabye|     1|  34|      |    |      278|\n",
      "|            5|Christine Jacoba ...|     2|  21|   185|  82|      705|\n",
      "|            6|     Per Knut Aaland|     1|  31|   188|  75|     1096|\n",
      "|            7|        John Aalberg|     1|  31|   183|  72|     1096|\n",
      "|            8|\"Cornelia \"\"Cor\"\"...|     2|  18|   168|    |      705|\n",
      "|            9|    Antti Sami Aalto|     1|  26|   186|  96|      350|\n",
      "|           10|\"Einar Ferdinand ...|     1|  26|      |    |      350|\n",
      "|           11|  Jorma Ilmari Aalto|     1|  22|   182|76.5|      350|\n",
      "|           12|   Jyri Tapani Aalto|     1|  31|   172|  70|      350|\n",
      "|           13|  Minna Maarit Aalto|     2|  30|   159|55.5|      350|\n",
      "|           14|Pirjo Hannele Aal...|     2|  32|   171|  65|      350|\n",
      "|           15|Arvo Ossian Aaltonen|     1|  22|      |    |      350|\n",
      "|           16|Juhamatti Tapio A...|     1|  28|   184|  85|      350|\n",
      "|           17|Paavo Johannes Aa...|     1|  28|   175|  64|      350|\n",
      "|           18|Timo Antero Aaltonen|     1|  31|   189| 130|      350|\n",
      "|           19|Win Valdemar Aalt...|     1|  54|      |    |      350|\n",
      "|           20|  Kjetil Andr Aamodt|     1|  20|   176|  85|      742|\n",
      "+-------------+--------------------+------+----+------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vemos los primero registros del Data Frame:\n",
    "deportistaErrorDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que existen campos vacíos (literlmente vacíos) y debemos asignarles el valor 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos función que usaremos como 'udf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(z)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función que convierte al tipo de dato 'integer' y\n",
    "# si el campo es vacío, asigan el valor 'null -> None'\n",
    "def conversionEnteros(valor):\n",
    "    return int(valor) if len(valor) > 0 else None\n",
    "\n",
    "# Declaramos función conmo udf:\n",
    "conversionEnteros_udf = udf(lambda z: conversionEnteros(z) , IntegerType() )\n",
    "\n",
    "# Damos de alta la función udf:\n",
    "sqlContext.udf.register('conversionEnteros_udf', conversionEnteros_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicamos la función udf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deportista_id: string (nullable = false)\n",
      " |-- nombre: string (nullable = false)\n",
      " |-- genero: string (nullable = false)\n",
      " |-- edad: string (nullable = false)\n",
      " |-- altura: string (nullable = false)\n",
      " |-- peso: string (nullable = false)\n",
      " |-- equipo_id: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos el schema antes de aplicar la función udf:\n",
    "deportistaErrorDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|alturaUDF|\n",
      "+---------+\n",
      "|      180|\n",
      "|      170|\n",
      "|     null|\n",
      "|     null|\n",
      "|      185|\n",
      "|      188|\n",
      "|      183|\n",
      "|      168|\n",
      "|      186|\n",
      "|     null|\n",
      "|      182|\n",
      "|      172|\n",
      "|      159|\n",
      "|      171|\n",
      "|     null|\n",
      "|      184|\n",
      "|      175|\n",
      "|      189|\n",
      "|     null|\n",
      "|      176|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos la función udf a la columna 'altura'\n",
    "deportistaErrorDF.select( conversionEnteros_udf('altura').alias('alturaUDF') ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerramos sesión para liberar memoria:\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
